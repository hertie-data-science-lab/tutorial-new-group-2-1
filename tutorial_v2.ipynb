{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hertie-data-science-lab/tutorial-new-group-2-1/blob/xiaohan-modeling/tutorial_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial: Transfer Learning for Flood Mapping Using Sentinel-1 Radar Imagery\n",
        "\n",
        "\n",
        "# GRAD-E1394 Deep Learning - Assignment 3\n",
        "\n",
        "Authors:\n",
        "\n",
        "\n",
        "*   Aditi Joshi\n",
        "*   Elena Murray\n",
        "*   Leticia Figueiredo Collado\n",
        "*   Sattiki Ganguly\n",
        "*   Xiaohan Wu\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BPrPCBoKoVny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test - check commit."
      ],
      "metadata": {
        "id": "seIIHEFETwi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil ls gs://sen1floods11/v1.1/catalog/sen1floods11_hand_labeled_label/ > chip_list.txt\n",
        "\n",
        "with open(\"chip_list.txt\") as f:\n",
        "    chip_dirs = [line.strip() for line in f]\n",
        "\n",
        "country_dirs = [d for d in chip_dirs if \"india\" in d.lower()]\n",
        "\n",
        "chip_ids = [d.rstrip(\"/\").split(\"/\")[-1].replace(\"_label\", \"\")\n",
        "            for d in country_dirs]\n",
        "\n",
        "print(f\"Found {len(chip_ids)} India chips\")\n",
        "print(\"Example:\", chip_ids[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9pPym85uVKX",
        "outputId": "dc315427-f574-43d4-bbb9-cece2ad79a61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 68 India chips\n",
            "Example: ['India_1017769', 'India_1018317', 'India_1018327', 'India_103447', 'India_1050276']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as F\n",
        "import torchvision.transforms as T\n",
        "import random\n",
        "\n",
        "# GCS streaming prefixes\n",
        "HTTP_PREFIX = \"https://storage.googleapis.com/sen1floods11/v1.1\"\n",
        "S1_PREFIX    = f\"/vsicurl/{HTTP_PREFIX}/data/flood_events/HandLabeled/S1Hand\"\n",
        "LABEL_PREFIX = f\"/vsicurl/{HTTP_PREFIX}/data/flood_events/HandLabeled/LabelHand\"\n",
        "\n",
        "class Sentinel1FloodDataset(Dataset):\n",
        "    def __init__(self, id_list):\n",
        "        self.ids = id_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        cid = self.ids[idx]\n",
        "\n",
        "        s1_path    = f\"{S1_PREFIX}/{cid}_S1Hand.tif\"\n",
        "        label_path = f\"{LABEL_PREFIX}/{cid}_LabelHand.tif\"\n",
        "\n",
        "        # --- Load Sentinel-1 SAR image (VV/VH) ---\n",
        "        with rasterio.open(s1_path) as src:\n",
        "            s1_img = src.read().astype(\"float32\")  # (2, 512, 512)\n",
        "\n",
        "        # Robust SAR normalization\n",
        "        s1_img = np.nan_to_num(s1_img)\n",
        "        s1_img = np.clip(s1_img, -50, 50)\n",
        "        s1_img = np.log1p(s1_img - s1_img.min())\n",
        "        s1_img = (s1_img - s1_img.mean()) / (s1_img.std() + 1e-6)\n",
        "\n",
        "        # --- Load flood mask ---\n",
        "        with rasterio.open(label_path) as src:\n",
        "            mask_raw = src.read(1).astype(\"int16\")\n",
        "\n",
        "        valid_mask = (mask_raw != -1)\n",
        "        label = (mask_raw == 1).astype(\"float32\")\n",
        "\n",
        "        x = torch.tensor(s1_img, dtype=torch.float32)\n",
        "        y = torch.tensor(label, dtype=torch.float32)[None, ...]\n",
        "        valid = torch.tensor(valid_mask, dtype=torch.bool)[None, ...]\n",
        "\n",
        "        return x, y, valid"
      ],
      "metadata": {
        "id": "JKBD4lzxtZzT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_pil_pair(x, y, valid):\n",
        "    vv = x[0].cpu().numpy()\n",
        "    vh = x[1].cpu().numpy()\n",
        "    label_arr = y[0].cpu().numpy()\n",
        "    valid_arr = valid[0].cpu().numpy().astype(np.uint8)\n",
        "\n",
        "    vv_pil = Image.fromarray((vv * 255).astype(np.uint8))\n",
        "    vh_pil = Image.fromarray((vh * 255).astype(np.uint8))\n",
        "    label_pil = Image.fromarray((label_arr * 255).astype(np.uint8))\n",
        "    valid_pil = Image.fromarray((valid_arr * 255).astype(np.uint8))\n",
        "\n",
        "    return vv_pil, vh_pil, label_pil, valid_pil"
      ],
      "metadata": {
        "id": "9qdNC7GjthkR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_train(x, y, valid):\n",
        "    vv_pil, vh_pil, label_pil, valid_pil = tensor_to_pil_pair(x, y, valid)\n",
        "\n",
        "    # Random flip (safe)\n",
        "    if random.random() > 0.5:\n",
        "        vv_pil    = F.hflip(vv_pil)\n",
        "        vh_pil    = F.hflip(vh_pil)\n",
        "        label_pil = F.hflip(label_pil)\n",
        "        valid_pil = F.hflip(valid_pil)\n",
        "\n",
        "    if random.random() > 0.5:\n",
        "        vv_pil    = F.vflip(vv_pil)\n",
        "        vh_pil    = F.vflip(vh_pil)\n",
        "        label_pil = F.vflip(label_pil)\n",
        "        valid_pil = F.vflip(valid_pil)\n",
        "\n",
        "    # Convert back to tensors\n",
        "    vv    = F.to_tensor(vv_pil).squeeze(0)\n",
        "    vh    = F.to_tensor(vh_pil).squeeze(0)\n",
        "    label = F.to_tensor(label_pil).round().squeeze(0)\n",
        "    valid = F.to_tensor(valid_pil).round().squeeze(0).bool()\n",
        "\n",
        "    x_aug = torch.stack([vv, vh], dim=0)\n",
        "    y_aug = label.unsqueeze(0)\n",
        "    valid_aug = valid.unsqueeze(0)\n",
        "\n",
        "    return x_aug, y_aug, valid_aug"
      ],
      "metadata": {
        "id": "q1qF5YNit2V6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_test(x, y, valid):\n",
        "    return x, y, valid"
      ],
      "metadata": {
        "id": "jDarpVMbt6Nw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AugmentedSentinel1Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, base_dataset, augment=False):\n",
        "        self.base = base_dataset\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y, valid = self.base[idx]\n",
        "\n",
        "        if self.augment:\n",
        "            return augment_train(x, y, valid)\n",
        "\n",
        "        else:\n",
        "            return preprocess_test(x, y, valid)"
      ],
      "metadata": {
        "id": "2y4RLdTKt-DD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_ids = sorted(chip_ids)\n",
        "\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(valid_ids)\n",
        "\n",
        "n = len(valid_ids)\n",
        "train_ids = valid_ids[:int(0.7*n)]\n",
        "val_ids   = valid_ids[int(0.7*n):int(0.85*n)]\n",
        "test_ids  = valid_ids[int(0.85*n):]\n",
        "\n",
        "print(f\"Train: {len(train_ids)}  Val: {len(val_ids)}  Test: {len(test_ids)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwGhksuguPsV",
        "outputId": "f38a8dcf-ce9a-4bb9-8ff5-165681b138df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 47  Val: 10  Test: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "\n",
        "train_ds = AugmentedSentinel1Dataset(Sentinel1FloodDataset(train_ids), augment=True)\n",
        "val_ds   = AugmentedSentinel1Dataset(Sentinel1FloodDataset(val_ids),   augment=False)\n",
        "test_ds  = AugmentedSentinel1Dataset(Sentinel1FloodDataset(test_ids),  augment=False)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_dl   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
        "test_dl  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "fm52Yv_Nt_1L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# U-Net with ResNet34 encoder pre-trained on ImageNet  ← TRANSFER LEARNING\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",\n",
        "    encoder_weights=\"imagenet\",   # this is the transfer part\n",
        "    in_channels=2,                # VV + VH\n",
        "    classes=1                     # binary mask\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "cfb4fdb8b4ff452baa2241d36dff5de1",
            "e3ff761cd00b46199c6550c347f9f471",
            "542033bb5e174c6d823d65dbef389d8c",
            "f3189230c8c54d3fb1f10ae9f9646f76",
            "a4d6ce7385fe4b589c0d110d160603ec",
            "57a6600c10cd44ea97e68ace0b207b30",
            "36045260e98c4bd097ab3977b8bbf0be",
            "3f970b2885064946a51cd73bbedafdd9",
            "75099aa680494b638a6d6b304991c2ab",
            "20a17659484341b085cd4842bb75c12d",
            "61d0a7d126704eb68d94af55c02914d4",
            "da412c022f8f49ab9c6d5629298fdcfb",
            "9100c65313bb43f5806eeb473c5b9188",
            "c3553671973643a294e12f4f2e00ff9f",
            "364beb40ce1843359b85b576b33d1e32",
            "5c86cdab7e42434baccbde6d41eb1c58",
            "2d8d17a3b0b648068b434f3557d66012",
            "a5aaf3fb49624c01af7e4d4cf8486137",
            "a3dc138112e14ff7b847e4809f74a672",
            "17f8a69931a3413ca7e34612a05d2011",
            "22621037bc4d4daea7664847fbde745e",
            "4d648a8a81a648f390f1592943bf38b6"
          ]
        },
        "id": "OpglqQeQuale",
        "outputId": "4ef3617e-ee24-41e1-946e-e858ce77ab32"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfb4fdb8b4ff452baa2241d36dff5de1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/87.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da412c022f8f49ab9c6d5629298fdcfb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou_from_logits(logits, target, valid):\n",
        "    \"\"\"\n",
        "    logits: (B,1,H,W)\n",
        "    target: (B,1,H,W) with 0/1\n",
        "    valid:  (B,1,H,W) bool\n",
        "    \"\"\"\n",
        "    probs = torch.sigmoid(logits)\n",
        "    preds = (probs > 0.5).float()\n",
        "\n",
        "    v = valid.bool()\n",
        "    if v.sum() == 0:\n",
        "        return torch.tensor(0.0, device=logits.device)\n",
        "\n",
        "    p = preds[v]\n",
        "    t = target[v]\n",
        "\n",
        "    intersection = (p * t).sum()\n",
        "    union = p.sum() + t.sum() - intersection\n",
        "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def compute_accuracy_from_logits(logits, target, valid):\n",
        "    probs = torch.sigmoid(logits)\n",
        "    preds = (probs > 0.5).float()\n",
        "\n",
        "    v = valid.bool()\n",
        "    if v.sum() == 0:\n",
        "        return torch.tensor(0.0, device=logits.device)\n",
        "\n",
        "    p = preds[v]\n",
        "    t = target[v]\n",
        "\n",
        "    correct = (p == t).float().sum()\n",
        "    acc = correct / p.numel()\n",
        "    return acc"
      ],
      "metadata": {
        "id": "Q1lEehOvuphM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dl, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_iou = 0.0\n",
        "    total_acc = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    for x, y, valid in dl:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        valid = valid.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)  # (B,1,H,W)\n",
        "\n",
        "        if valid.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        loss = criterion(logits[valid], y[valid])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iou = compute_iou_from_logits(logits, y, valid).item()\n",
        "        acc = compute_accuracy_from_logits(logits, y, valid).item()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_iou  += iou\n",
        "        total_acc  += acc\n",
        "        n_batches  += 1\n",
        "\n",
        "    if n_batches == 0:\n",
        "        return 0.0, 0.0, 0.0\n",
        "\n",
        "    return (\n",
        "        total_loss / n_batches,\n",
        "        total_iou  / n_batches,\n",
        "        total_acc  / n_batches,\n",
        "    )\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_one_epoch(model, dl):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_iou = 0.0\n",
        "    total_acc = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    for x, y, valid in dl:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        valid = valid.to(device)\n",
        "\n",
        "        logits = model(x)\n",
        "\n",
        "        if valid.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        loss = criterion(logits[valid], y[valid])\n",
        "        iou = compute_iou_from_logits(logits, y, valid).item()\n",
        "        acc = compute_accuracy_from_logits(logits, y, valid).item()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_iou  += iou\n",
        "        total_acc  += acc\n",
        "        n_batches  += 1\n",
        "\n",
        "    if n_batches == 0:\n",
        "        return 0.0, 0.0, 0.0\n",
        "\n",
        "    return (\n",
        "        total_loss / n_batches,\n",
        "        total_iou  / n_batches,\n",
        "        total_acc  / n_batches,\n",
        "    )"
      ],
      "metadata": {
        "id": "AKrxIeKhurr_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze encoder → only train decoder/head (classic transfer learning warmup)\n",
        "for p in model.encoder.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-3,\n",
        ")\n",
        "\n",
        "print(\"=== Stage 1: Train Decoder Only (Frozen Encoder) ===\")\n",
        "num_epochs_stage1 = 3\n",
        "\n",
        "for epoch in range(num_epochs_stage1):\n",
        "    tr_loss, tr_iou, tr_acc = train_one_epoch(model, train_dl, optimizer)\n",
        "    va_loss, va_iou, va_acc = validate_one_epoch(model, val_dl)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_stage1}\")\n",
        "    print(f\"  Train - Loss: {tr_loss:.4f}, IoU: {tr_iou:.4f}, Acc: {tr_acc:.4f}\")\n",
        "    print(f\"  Val   - Loss: {va_loss:.4f}, IoU: {va_iou:.4f}, Acc: {va_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqJnSK4Iutwa",
        "outputId": "bf2dc1a4-86ab-4490-b1de-3ebc5e1c66c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Stage 1: Train Decoder Only (Frozen Encoder) ===\n",
            "Epoch 1/3\n",
            "  Train - Loss: 0.9641, IoU: 0.1244, Acc: 0.3680\n",
            "  Val   - Loss: 1.4792, IoU: 0.1625, Acc: 0.2651\n",
            "Epoch 2/3\n",
            "  Train - Loss: 0.5743, IoU: 0.0978, Acc: 0.8034\n",
            "  Val   - Loss: 0.5515, IoU: 0.1731, Acc: 0.8098\n",
            "Epoch 3/3\n",
            "  Train - Loss: 0.4646, IoU: 0.0198, Acc: 0.8611\n",
            "  Val   - Loss: 0.6749, IoU: 0.0271, Acc: 0.7863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_test_iou():\n",
        "    model.eval()\n",
        "    ious = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y, valid in test_dl:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            valid = valid.to(device)\n",
        "\n",
        "            logits = model(x)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).float()\n",
        "\n",
        "            # compute IoU only on valid pixels\n",
        "            v = valid.bool()\n",
        "            if v.sum() == 0:\n",
        "                continue\n",
        "\n",
        "            pred_v = preds[v]\n",
        "            y_v = y[v]\n",
        "\n",
        "            intersection = (pred_v * y_v).sum()\n",
        "            union = pred_v.sum() + y_v.sum() - intersection\n",
        "            iou = (intersection / (union + 1e-6)).item()\n",
        "            ious.append(iou)\n",
        "\n",
        "    return sum(ious) / len(ious)\n",
        "\n",
        "test_iou = eval_test_iou()\n",
        "print(f\"\\nFinal Test IoU (valid pixels only): {test_iou:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLAwlMjbzi-Y",
        "outputId": "4d9b885c-a828-40be-b82e-3db8532704db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test IoU (valid pixels only): 0.0112\n"
          ]
        }
      ]
    }
  ]
}
